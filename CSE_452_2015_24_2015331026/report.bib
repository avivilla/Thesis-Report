@inproceedings{cite1,
title = "RDRPOSTagger: A Ripple Down Rules-based Part-Of-Speech Tagger",
abstract = "This paper describes our robust, easyto-use and language independent toolkit namely RDRPOSTagger which employs an error-driven approach to automatically construct a Single Classification Ripple Down Rules tree of transformation rules for POS tagging task. During the demonstration session, we will run the tagger on data sets in 15 different languages.",
author = "Nguyen, {Dat Quoc} and Nguyen, {Dai Quoc} and Pham, {Dang Duc} and Pham, {Son Bao}",
year = "2014",
language = "English",
isbn = "9781937284756",
pages = "17--20",
booktitle = "EACL 2014",
publisher = "Association for Computational Linguistics (ACL)",
}
@article{cite2,
  title={A robust transformation-based learning approach using ripple down rules for part-of-speech tagging},
  author={Nguyen, Dat Quoc and Nguyen, Dai Quoc and Pham, Dang Duc and Pham, Son Bao},
  journal={AI Communications},
  volume={29},
  number={3},
  pages={409--422},
  year={2016},
  publisher={IOS Press}
}
@incollection{cite3,
  title={Improvements in part-of-speech tagging with an application to German},
  author={Schmid, Helmut},
  booktitle={Natural language processing using very large corpora},
  pages={13--25},
  year={1999},
  publisher={Springer}
}
@inproceedings{cite4,
  title={The Stanford CoreNLP natural language processing toolkit},
  author={Manning, Christopher and Surdeanu, Mihai and Bauer, John and Finkel, Jenny and Bethard, Steven and McClosky, David},
  booktitle={Proceedings of 52nd annual meeting of the association for computational linguistics: system demonstrations},
  pages={55--60},
  year={2014}
}
@inproceedings{cite5,
  title={Word sense disambiguation based on word similarity calculation using word vector representation from a knowledge-based graph},
  author={Dongsuk, O and Kwon, Sunjae and Kim, Kyungsun and Ko, Youngjoong},
  booktitle={Proceedings of the 27th International Conference on Computational Linguistics},
  pages={2704--2714},
  year={2018}
}
@inproceedings{cite6,
  title={Hidden markov model for pos tagging in word sense disambiguation},
  author={Alva, Pooja and Hegde, Vinay},
  booktitle={2016 International Conference on Computation System and Information Technology for Sustainable Solutions (CSITSS)},
  pages={279--284},
  year={2016},
  organization={IEEE}
}
@inproceedings{dandapat2004hybrid,
  title={A Hybrid Model for Part-of-Speech Tagging and its Application to Bengali.},
  author={Dandapat, Sandipan and Sarkar, Sudeshna and Basu, Anupam},
  booktitle={International conference on computational intelligence},
  pages={169--172},
  year={2004},
  organization={Citeseer}
}
@inproceedings{ekbal2007bengali,
  title={Bengali part of speech tagging using conditional random field},
  author={Ekbal, Asif and Haque, Rejwanul and Bandyopadhyay, Sivaji},
  booktitle={Proceedings of Seventh International Symposium on Natural Language Processing (SNLP2007)},
  pages={131--136},
  year={2007}
}
@INPROCEEDINGS{ekbalsvm, 
author={A. {Ekbal} and S. {Bandyopadhyay}}, 
booktitle={2008 International Conference on Information Technology}, 
title={Part of Speech Tagging in Bengali Using Support Vector Machine}, 
year={2008}, 
volume={}, 
number={}, 
pages={106-111}, 
keywords={natural language processing;support vector machines;part of speech tagging;Bengali;support vector machine;word labeling;language processing activities;Indian languages;entity recognizer;Speech;Tagging;Support vector machines;Hidden Markov models;Stochastic processes;Natural languages;Information technology;Labeling;Computer science;Testing;Part of Speech (POS) tagging;Support Vector Machine;Bengali}, 
doi={10.1109/ICIT.2008.12}, 
ISSN={}, 
month={Dec},}
@INPROCEEDINGS{sarkar, 
author={K. {Sarkar} and V. {Gayen}}, 
booktitle={2012 Third International Conference on Emerging Applications of Information Technology}, 
title={A practical part-of-speech tagger for Bengali}, 
year={2012}, 
volume={}, 
number={}, 
pages={36-40}, 
keywords={hidden Markov models;learning (artificial intelligence);natural language processing;statistical analysis;text analysis;practical part-of-speech tagger;Bengali text;Bengali font;NLP applications;supervised Bengali trigram POS Tagger;statistical machine learning technique;Hidden Markov Model;HMM;Hidden Markov models;Tagging;Training;Equations;Natural language processing;Speech;Viterbi algorithm;Part-of-speech tagging;Second order hidden markov model;Bengali Language}, 
doi={10.1109/EAIT.2012.6407856}, 
ISSN={}, 
month={Nov},}
@INPROCEEDINGS{mukherjee, 
author={S. {Mukherjee} and S. K. {Das Mandal}}, 
booktitle={2013 Annual IEEE India Conference (INDICON)}, 
title={Bengali parts-of-speech tagging using Global Linear Model}, 
year={2013}, 
volume={}, 
number={}, 
pages={1-4}, 
keywords={natural language processing;vectors;Bengali parts-of-speech tagging;global linear model;automatic parts-of-speech tagging;Bengali sentences;feature vector;global feature;averaged perceptron algorithm;Hidden Markov models;Tagging;Support vector machines;Accuracy;Training;Vectors;Natural language processing;Global Linear Model;Bengali-POS tagger;Indian Languages}, 
doi={10.1109/INDCON.2013.6726132}, 
ISSN={2325-940X}, 
month={Dec},}
@article{chakrabarti2011layered,
  title={Layered parts of speech tagging for Bangla},
  author={Chakrabarti, Debasri and CDAC, Pune},
  journal={Language in India, www. languageinindia. com, Special Volume: Problems of Parsing in Indian Languages},
  year={2011}
}
@article{ekbal2008maximum,
  title={Maximum entropy based bengali part of speech tagging},
  author={Ekbal, Asif and Haque, Rejwanul and Bandyopadhyay, Sivaji},
  journal={A. Gelbukh (Ed.), Advances in Natural Language Processing and Applications, Research in Computing Science (RCS) Journal},
  volume={33},
  pages={67--78},
  year={2008}
}
@inproceedings{uddin,
author = {Nazim Uddin, Md and Islam, Md Saiful and Ahmad Khan, Moudud and Jannat, Marium-E},
year = {2018},
month = {09},
pages = {1-4},
title = {A Neural Network Approach for Bangla POS Tagger},
doi = {10.1109/ICBSLP.2018.8554771}
}
@inproceedings{ekbal2007lexicon,
  title={Lexicon Development and POS Tagging Using a Tagged Bengali News Corpus.},
  author={Ekbal, Asif and Bandyopadhyay, Sivaji},
  booktitle={FLAIRS Conference},
  pages={261--262},
  year={2007}
}
@inproceedings{de1959file,
  title={File searching using variable length keys},
  author={De La Briandais, Rene},
  booktitle={Papers presented at the the March 3-5, 1959, western joint computer conference},
  pages={295--298},
  year={1959},
  organization={ACM}
}
@techreport{black1998dictionary,
  title={Dictionary of algorithms and data structures},
  author={Black, Paul E},
  year={1998}
}
@misc{ trie,
    author = "{Wikipedia contributors}",
    title = "Trie --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2019",
    url = "https://en.wikipedia.org/w/index.php?title=Trie&oldid=905392747",
    note = "[Online; accessed 13-July-2019]"
 }
@article{Kukich:1992:TAC:146370.146380,
 author = {Kukich, Karen},
 title = {Techniques for Automatically Correcting Words in Text},
 journal = {ACM Comput. Surv.},
 issue_date = {Dec. 1992},
 volume = {24},
 number = {4},
 month = dec,
 year = {1992},
 issn = {0360-0300},
 pages = {377--439},
 numpages = {63},
 url = {http://doi.acm.org/10.1145/146370.146380},
 doi = {10.1145/146370.146380},
 acmid = {146380},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {n-gram analysis, Optical Character Recognition (OCR), context-dependent spelling correction, grammar checking, natural-language-processing models, neural net classifiers, spell checking, spelling error detection, spelling error patterns, statistical-language models, word recognition and correction},
}
@article{navarro,
author = {Navarro, Gonzalo},
year = {2000},
month = {04},
pages = {},
title = {A Guided Tour to Approximate String Matching},
volume = {33},
journal = {ACM Computing Surveys},
doi = {10.1145/375360.375365}
}
@article{fastalgo,
author = {Landau, G. and Myers, E. and Schmidt, J.},
title = {Incremental String Comparison},
journal = {SIAM Journal on Computing},
volume = {27},
number = {2},
pages = {557-582},
year = {1998},
doi = {10.1137/S0097539794264810},

URL = { 
        https://doi.org/10.1137/S0097539794264810
    
},
eprint = { 
        https://doi.org/10.1137/S0097539794264810
    
}

}
@MISC{Manacher_alinear,
    author = {G. Manacher and D. S. Hirschberg},
    title = {A Linear Space Algorithm for Computing Maximal Common Subsequences},
    year = {}
}

@misc{Charles2013,
  author = {Charles, P.W.D.},
  title = {Project Title},
  year = {2013},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/charlespwd/project-title}},
  commit = {4f57d6a0e4c030202a07a60bc1bb1ed1544bf679}
}
@article{doi:10.1162/neco.1997.9.8.1735,
author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
title = {Long Short-Term Memory},
journal = {Neural Computation},
volume = {9},
number = {8},
pages = {1735-1780},
year = {1997},
doi = {10.1162/neco.1997.9.8.1735},

URL = { 
        https://doi.org/10.1162/neco.1997.9.8.1735
    
},
eprint = { 
        https://doi.org/10.1162/neco.1997.9.8.1735
    
}
,
    abstract = { Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms. }
}

@misc{ma2016endtoend,
    title={End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF},
    author={Xuezhe Ma and Eduard Hovy},
    year={2016},
    eprint={1603.01354},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{huang2015bidirectional,
    title={Bidirectional LSTM-CRF Models for Sequence Tagging},
    author={Zhiheng Huang and Wei Xu and Kai Yu},
    year={2015},
    eprint={1508.01991},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}
@misc{plank2016multilingual,
    title={Multilingual Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Models and Auxiliary Loss},
    author={Barbara Plank and Anders Søgaard and Yoav Goldberg},
    year={2016},
    eprint={1604.05529},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}
@misc{wang2015unified,
    title={A Unified Tagging Solution: Bidirectional LSTM Recurrent Neural Network with Word Embedding},
    author={Peilu Wang and Yao Qian and Frank K. Soong and Lei He and Hai Zhao},
    year={2015},
    eprint={1511.00215},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}